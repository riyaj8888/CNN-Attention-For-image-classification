{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_classification_with_CNN+Attention Model",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "environment": {
      "name": "tf2-gpu.2-4.m61",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m61"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq-gTE-uBtXC"
      },
      "source": [
        "# Image classification with CNN+Attention Hybrid Model\n",
        "\n",
        "**Author:** [RIYAJ ATAR]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E8ZXYWufDFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2a69f85-9b69-40a5-c3fc-01d9fbf69b27"
      },
      "source": [
        "!pip install -U tensorflow-addons"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 34.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 61 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 348 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 378 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 409 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 440 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 471 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 501 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 522 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 542 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 563 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 583 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 604 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 624 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 634 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 645 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 655 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 665 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 675 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 679 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5P2vw2QBtXF"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUrSOCUNBtXF"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aCipVZABtXG"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nANkPcNNBtXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "629471fd-85e4-436e-cedf-87be9ee9d42c"
      },
      "source": [
        "num_classes = 100\n",
        "input_shape = (32, 32, 3)\n",
        "image_size = 72\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXHtxwnF716C"
      },
      "source": [
        "## Attention applied on Feature Maps of CNN output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hRTNRuZ7nBT"
      },
      "source": [
        "\n",
        "def attention_weight(f,num_heads = 8):\n",
        "\n",
        "  x1 = layers.Reshape([f.shape[1]*f.shape[2],f.shape[3]])(f)\n",
        "\n",
        "  attention_output = layers.MultiHeadAttention(\n",
        "      num_heads=num_heads, key_dim=f.shape[3], dropout=0.1\n",
        "  )(x1, x1)\n",
        "\n",
        "  x1 = layers.Reshape([f.shape[1],f.shape[2],f.shape[3]])(x1)\n",
        "\n",
        "  f = layers.Multiply()([f,x1])\n",
        "\n",
        "  return f"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu3BSAVsBtXG"
      },
      "source": [
        "## Configure the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVGzC28IBtXG"
      },
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 256\n",
        "num_epochs = 100\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlC29thCBtXH"
      },
      "source": [
        "## Use data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXHfGvny7uf7"
      },
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.Normalization(),\n",
        "        layers.experimental.preprocessing.Resizing(image_size, image_size),\n",
        "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "        layers.experimental.preprocessing.RandomRotation(factor=0.02),\n",
        "        layers.experimental.preprocessing.RandomZoom(\n",
        "            height_factor=0.2, width_factor=0.2\n",
        "        ),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(x_train)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViGtsipi8h03"
      },
      "source": [
        "## Define keras model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbVbAjip8lg5",
        "outputId": "060d4257-66a6-46ac-bd17-a89b653ae9d6"
      },
      "source": [
        "\n",
        "\n",
        "def model_cifar100():\n",
        "\n",
        "  x = layers.Input(shape=(32,32,3))\n",
        "\n",
        "  inputs = data_augmentation(x)\n",
        "\n",
        "\n",
        "  # l = AveragePooling2D\n",
        "\n",
        "  f = layers.Conv2D(16,3,1,'same',activation = 'relu')(inputs)\n",
        "  f = layers.Conv2D(16,3,2,'same',activation = 'relu')(f) \n",
        "  f = layers.BatchNormalization()(f)\n",
        "  # p1 = l(pool_size=2)(x)\n",
        "  # f = Concatenate(axis=3)([f,p1])\n",
        "\n",
        "  f = layers.Conv2D(32,3,1,'same',activation = 'relu')(f)\n",
        "  f = layers.Conv2D(32,3,2,'same',activation = 'relu')(f) \n",
        "  f = layers.BatchNormalization()(f)\n",
        "\n",
        "  # p2 =  l(pool_size=4)(x)\n",
        "  # f = Concatenate(axis=3)([f,p2])\n",
        "\n",
        "\n",
        "  f = layers.Conv2D(64,3,1,'same',activation = 'relu')(f)\n",
        "  f = layers.Conv2D(64,3,2,'same',activation = 'relu')(f) \n",
        "  f = layers.BatchNormalization()(f)\n",
        "\n",
        "  # p3 =  l(pool_size=8)(x)\n",
        "  # f = Concatenate(axis=3)([f,p3])\n",
        "  f = attention_weight(f,num_heads=8)\n",
        "\n",
        "  f = layers.Conv2D(128,3,1,'same',activation = 'relu')(f)\n",
        "  f = layers.Conv2D(128,3,2,'same',activation = 'relu')(f) \n",
        "  f = layers.BatchNormalization()(f)\n",
        "\n",
        "  # p4 =  l(pool_size=16)(x)\n",
        "  # f = Concatenate(axis=3)([f,p4])\n",
        "  f = attention_weight(f,num_heads=16)\n",
        "\n",
        "  representation = layers.Flatten()(f)\n",
        "  representation = layers.Dropout(0.5)(representation)\n",
        "\n",
        "\n",
        "  logits = layers.Dense(100)(representation)\n",
        "  model = keras.Model(inputs = x,outputs = logits)\n",
        "\n",
        "  return model\n",
        "\n",
        "model = model_cifar100()\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "data_augmentation (Sequential)  (None, 72, 72, 3)    7           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 72, 72, 16)   448         data_augmentation[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 36, 36, 16)   2320        conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 36, 36, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 36, 36, 32)   4640        batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 18, 18, 32)   9248        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 18, 18, 32)   128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 18, 18, 64)   18496       batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 9, 9, 64)     36928       conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 9, 9, 64)     256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 81, 64)       0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 9, 9, 64)     0           reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 9, 9, 64)     0           batch_normalization_2[0][0]      \n",
            "                                                                 reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 9, 9, 128)    73856       multiply[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 5, 5, 128)    147584      conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 5, 5, 128)    512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 25, 128)      0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 5, 5, 128)    0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 5, 5, 128)    0           batch_normalization_3[0][0]      \n",
            "                                                                 reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 3200)         0           multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 3200)         0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          320100      dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 614,587\n",
            "Trainable params: 614,100\n",
            "Non-trainable params: 487\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRyyX5DKBtXL"
      },
      "source": [
        "## Compile, train, and evaluate the mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWMJvgxEBtXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "769bc944-8835-40c9-cfcd-a198a024107a"
      },
      "source": [
        "\n",
        "def run_experiment(model):\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "history = run_experiment(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}